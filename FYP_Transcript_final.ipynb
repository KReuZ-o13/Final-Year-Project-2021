{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FYP_Transcript_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZgqAUDAxyMI",
        "outputId": "36812fe1-3e7e-4b93-f322-ad6e7c996fe9"
      },
      "source": [
        "!pip install webrtcvad\r\n",
        "!pip install deepspeech"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting webrtcvad\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/34/e2de2d97f3288512b9ea56f92e7452f8207eb5a0096500badf9dfd48f5e6/webrtcvad-2.0.10.tar.gz (66kB)\n",
            "\r\u001b[K     |█████                           | 10kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=72334 sha256=801953264b7e650555c275b81366adc6e0ca0aa6086b20e37cfacd104e9af070\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/2a/18/bd1aec41cac7c3051fe95d92a6ed446122ea31dc713c432fa1\n",
            "Successfully built webrtcvad\n",
            "Installing collected packages: webrtcvad\n",
            "Successfully installed webrtcvad-2.0.10\n",
            "Collecting deepspeech\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ca/5ac1f4b31f8b7721be20b692341fa6088c875e40f1cd0c0a27837b058f96/deepspeech-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (9.2MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from deepspeech) (1.19.5)\n",
            "Installing collected packages: deepspeech\n",
            "Successfully installed deepspeech-0.9.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-dXa1QOyhe3",
        "outputId": "803a651b-6906-4a74-d24c-745a06d386bb"
      },
      "source": [
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\r\n",
        "!wget https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-03 19:05:28--  https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/60273704/8b25f180-3b0f-11eb-8fc1-de4f4ec3b5a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210303%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210303T190528Z&X-Amz-Expires=300&X-Amz-Signature=72fbdc7d3ad216504db2a63540b4c2d9c19ea0a88cb5003563f5f38c897ec182&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.pbmm&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-03-03 19:05:28--  https://github-releases.githubusercontent.com/60273704/8b25f180-3b0f-11eb-8fc1-de4f4ec3b5a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210303%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210303T190528Z&X-Amz-Expires=300&X-Amz-Signature=72fbdc7d3ad216504db2a63540b4c2d9c19ea0a88cb5003563f5f38c897ec182&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.pbmm&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.110.154, 185.199.109.154, 185.199.111.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.110.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 188915987 (180M) [application/octet-stream]\n",
            "Saving to: ‘deepspeech-0.9.3-models.pbmm’\n",
            "\n",
            "deepspeech-0.9.3-mo 100%[===================>] 180.16M  21.0MB/s    in 13s     \n",
            "\n",
            "2021-03-03 19:05:42 (13.4 MB/s) - ‘deepspeech-0.9.3-models.pbmm’ saved [188915987/188915987]\n",
            "\n",
            "--2021-03-03 19:05:42--  https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/60273704/924cff80-3b0f-11eb-878c-cacaa2a0d946?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210303%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210303T190542Z&X-Amz-Expires=300&X-Amz-Signature=95e0237b3358c7d338d05f8824fe951698586d65d3facd3d349cfdb3b680cc68&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.scorer&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-03-03 19:05:42--  https://github-releases.githubusercontent.com/60273704/924cff80-3b0f-11eb-878c-cacaa2a0d946?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210303%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210303T190542Z&X-Amz-Expires=300&X-Amz-Signature=95e0237b3358c7d338d05f8824fe951698586d65d3facd3d349cfdb3b680cc68&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=60273704&response-content-disposition=attachment%3B%20filename%3Ddeepspeech-0.9.3-models.scorer&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 953363776 (909M) [application/octet-stream]\n",
            "Saving to: ‘deepspeech-0.9.3-models.scorer’\n",
            "\n",
            "deepspeech-0.9.3-mo 100%[===================>] 909.20M  26.1MB/s    in 38s     \n",
            "\n",
            "2021-03-03 19:06:20 (24.1 MB/s) - ‘deepspeech-0.9.3-models.scorer’ saved [953363776/953363776]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anRq3LJ3zuPV"
      },
      "source": [
        "import numpy as np\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import IPython\r\n",
        "import wave\r\n",
        "import json\r\n",
        "import webrtcvad\r\n",
        "import collections\r\n",
        "from deepspeech import Model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuyRsEsvz3bS",
        "outputId": "208db37e-2d25-44c9-ee14-7c5fed068f88"
      },
      "source": [
        "model_file_path = \"deepspeech-0.9.3-models.pbmm\"\r\n",
        "sc_file_path = \"deepspeech-0.9.3-models.scorer\"\r\n",
        "beam_width = 500\r\n",
        "sc_alpha = 0.93\r\n",
        "sc_beta = 1.18\r\n",
        "\r\n",
        "model = Model(model_file_path)\r\n",
        "model.enableExternalScorer(sc_file_path)\r\n",
        "\r\n",
        "model.setScorerAlphaBeta(sc_alpha, sc_beta)\r\n",
        "model.setBeamWidth(beam_width)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBkzP0IA0N07"
      },
      "source": [
        "#obtain input data\r\n",
        "#Check the audio parameters (rate at 16000, channels at mono)\r\n",
        "#Gets the audio duration and the data\r\n",
        "def input_read(filename):\r\n",
        "    with wave.open(filename, 'r') as s:\r\n",
        "        channels = s.getnchannels()\r\n",
        "        assert channels == 1\r\n",
        "        sample_width = s.getsampwidth()\r\n",
        "        assert sample_width == 2\r\n",
        "        rate = s.getframerate()\r\n",
        "        assert rate == 16000\r\n",
        "        frames = s.getnframes()\r\n",
        "        audio_data = s.readframes(frames)\r\n",
        "        duration = frames / rate\r\n",
        "    return audio_data, rate, duration     "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JlHfuDS0fCM"
      },
      "source": [
        "#Define an object called frames~\r\n",
        "#Used to store the instances we'll create from the frames\r\n",
        "class Frame(object):\r\n",
        "    def __init__(self, bytes, timestamp, duration):\r\n",
        "        self.bytes = bytes\r\n",
        "        self.timestamp = timestamp\r\n",
        "        self.duration = duration\r\n",
        "\r\n",
        "\r\n",
        "#So, deepspeech models need tiny chunks of data to work\r\n",
        "#This function is used to create those tiny chunks\r\n",
        "def segment_generator(frame_time, audio, rate):\r\n",
        "    n = int(rate * (frame_time / 1000.0) * 2)\r\n",
        "    offset = 0\r\n",
        "    timestamp = 0.0\r\n",
        "    duration = (float(n) / rate) / 2.0\r\n",
        "    while offset + n < len(audio):\r\n",
        "        yield Frame(audio[offset:offset + n], timestamp, duration)\r\n",
        "        timestamp += duration\r\n",
        "        offset += n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exeBJyDi0ke5"
      },
      "source": [
        "def vad_and_buffer(rate, frame_duration_ms, padding_duration_ms, vad, frames):\r\n",
        "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\r\n",
        "    # We use a deque for our sliding window/ring buffer.\r\n",
        "    ring_buffer = collections.deque(maxlen=num_padding_frames)\r\n",
        "    # We have two states: TRIGGERED and NOTTRIGGERED. We start in the\r\n",
        "    # NOTTRIGGERED state.\r\n",
        "    triggered = False\r\n",
        "\r\n",
        "    voiced_frames = []\r\n",
        "    for frame in frames:\r\n",
        "        is_speech = vad.is_speech(frame.bytes, rate)\r\n",
        "\r\n",
        "        if not triggered:\r\n",
        "            ring_buffer.append((frame, is_speech))\r\n",
        "            num_voiced = len([f for f, speech in ring_buffer if speech])\r\n",
        "            # If we're NOTTRIGGERED and more than 90% of the frames in\r\n",
        "            # the ring buffer are voiced frames, then enter the\r\n",
        "            # TRIGGERED state.\r\n",
        "            if num_voiced > 0.9 * ring_buffer.maxlen:\r\n",
        "                triggered = True\r\n",
        "                # We want to yield all the audio we see from now until\r\n",
        "                # we are NOTTRIGGERED, but we have to start with the\r\n",
        "                # audio that's already in the ring buffer.\r\n",
        "                for f, s in ring_buffer:\r\n",
        "                    voiced_frames.append(f)\r\n",
        "                ring_buffer.clear()\r\n",
        "        else:\r\n",
        "            # We're in the TRIGGERED state, so collect the audio data\r\n",
        "            # and add it to the ring buffer.\r\n",
        "            voiced_frames.append(frame)\r\n",
        "            ring_buffer.append((frame, is_speech))\r\n",
        "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\r\n",
        "            # If more than 90% of the frames in the ring buffer are\r\n",
        "            # unvoiced, then enter NOTTRIGGERED and yield whatever\r\n",
        "            # audio we've collected.\r\n",
        "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\r\n",
        "                triggered = False\r\n",
        "                yield b''.join([f.bytes for f in voiced_frames])\r\n",
        "                ring_buffer.clear()\r\n",
        "                voiced_frames = []\r\n",
        "    if triggered:\r\n",
        "        pass\r\n",
        "    # If we have any leftover voiced audio when we run out of input,\r\n",
        "    # yield it.\r\n",
        "    if voiced_frames:\r\n",
        "        yield b''.join([f.bytes for f in voiced_frames])\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slrRsGg80quq"
      },
      "source": [
        "def the_final_segment_generator(filename, aggressiveness):\r\n",
        "    audio, rate, audio_length = input_read(filename)\r\n",
        "    vad = webrtcvad.Vad(int(aggressiveness))\r\n",
        "    frames = segment_generator(30, audio, rate)\r\n",
        "    frames = list(frames)\r\n",
        "    segments = vad_and_buffer(rate, 30, 300, vad, frames)\r\n",
        "\r\n",
        "    return segments, rate, audio_length\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLZ0zrcvnNS7"
      },
      "source": [
        "def transcription (filename):\n",
        "  #This transcribes the audio segemnts and saves them to a list\n",
        "  segments, rate, audio_length = the_final_segment_generator(filename, 1)\n",
        "  one_list = []\n",
        "  for i, segment in enumerate(segments):\n",
        "    #run deepspeech on each segment and append it to a list\n",
        "    audio = np.frombuffer(segment, dtype = np.int16)\n",
        "    output = model.stt(audio)\n",
        "    one_list.append(output)\n",
        "  return (one_list)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B94UYLxUplRt",
        "outputId": "fb0d9f5b-094f-40dd-bd8d-5d6f4eaa1b01"
      },
      "source": [
        "file_name_1 = \"/content/diarization_cluster_0.wav\"\n",
        "file_name_2 = \"/content/diarization_cluster_1.wav\"\n",
        "text_1  = transcription(file_name_1)\n",
        "with open('transcript_1.txt', 'w') as f:\n",
        "  f.write(json.dumps(text_1))\n",
        "f.close\n",
        "\n",
        "text_2  = transcription(file_name_2)\n",
        "with open('transcript_2.txt', 'w') as f:\n",
        "  f.write(json.dumps(text_2))\n",
        "f.close"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}